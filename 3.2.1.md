#  MINIST手写数字识别（深度学习的helloword）

MNIST是一个简单的视觉计算数据集，它是像下面这样手写的数字图片：

![image](https://raw.githubusercontent.com/szliszt/AI_Study_Notes_ByCase/main/images/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97.webp)

用深度学习实现手写数字的识别

> 参考：
> 
> - 【深度学习】手写数字识别Tensorflow2实验报告		
>   https://blog.csdn.net/weixin_43935696/article/details/118440832
> - https://www.cnblogs.com/desedese/p/14312713.html
> - https://zhuanlan.zhihu.com/p/141239292


paddlepaddle代码:
> 版本1：
> 参考：
> paddle2.0高层API快速实现LeNet(MNIST手写数字识别)
> https://zhuanlan.zhihu.com/p/350525427

```python
import paddle
from paddle.vision.transforms import ToTensor

# 加载数据集
train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())
val_dataset =  paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())

# 查看数据集
for batch_id, data in enumerate(val_dataset):
    x_data = data[0] # 图像数据
    y_data = data[1] # 标签
    print(x_data.shape)
    print(y_data)
    
# 模型组网
mnist = paddle.nn.Sequential(
    paddle.nn.Flatten(),
    paddle.nn.Linear(784, 512),
    paddle.nn.ReLU(),
    paddle.nn.Dropout(0.2),
    paddle.nn.Linear(512, 10)
)

# 封装模型
model = paddle.Model(mnist)

# 配置训练模型
model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),
              paddle.nn.CrossEntropyLoss(),
              paddle.metric.Accuracy())

# 模型训练
model.fit(train_dataset,
          epochs=5,
          batch_size=64,
          verbose=1)
# 模型评估
model.evaluate(val_dataset, verbose=0)
 
# 模型测试
result=model.predict(val_dataset)
# 查看第5张图片的预测结果
print("查看结果的数据结构:")
print(type(result))

import matplotlib.pyplot as plt
import numpy as np

# 定义画图方法
def show_img(img, predict):
    plt.figure()
    plt.title('predict:{}'.format(predict))
    plt.imshow(img.reshape([28, 28]), cmap=plt.cm.binary)
    plt.show()

# 抽样展示
indexs = [2, 15, 38, 211]

for idx in indexs:
    show_img(val_dataset[idx][0], np.argmax(result[0][idx]))

```



版本2:
> 参考:
> https://aistudio.baidu.com/aistudio/projectdetail/1926913

```python

import paddle as pdl
import numpy as np
import cv2 as cv
from tqdm import tqdm
import paddle.vision.transforms as T

transform = T.Normalize(mean = [127.5], std = [127.5])
training_set = pdl.vision.datasets.MNIST(mode = 'train', transform = transform)
testing_set = pdl.vision.datasets.MNIST(mode = 'test', transform = transform)
print('Num of training set: {}, num of testing set: {}'.format(len(training_set), len(testing_set)))
# data set and packages(partly) has been loaded

# type of training_set is an object list containing 60000 images message
# which is saved as a 2 dimensions array(but it has a shell) and a 1x1 array
# take training_set[0] for example, it is [[2 dimensions array], [5]]


import matplotlib.pyplot as plt
plt.figure()
plt.imshow(training_set[0][0][0], cmap = plt.cm.binary)# it has a shell so we need to add a '[0]' to peel off its shell
plt.show()

# neural network model net1
net1 = pdl.nn.Sequential(
    pdl.nn.Flatten(), pdl.nn.Linear(784, 100), pdl.nn.ReLU(),
    pdl.nn.Linear(100, 100), pdl.nn.ReLU(),
    pdl.nn.Linear(100, 10), pdl.nn.Softmax()
)
# convolution neural network model net2
net2 = pdl.nn.Sequential(
    pdl.nn.Conv2D(1, 6, (5, 5)), pdl.nn.MaxPool2D(kernel_size = 2),
    pdl.nn.Conv2D(6, 16, (5, 5)), pdl.nn.MaxPool2D(kernel_size = 2),
    pdl.nn.Flatten(), pdl.nn.Linear(256, 120),
    pdl.nn.Linear(120, 60),
    pdl.nn.Linear(60, 10),
    pdl.nn.Softmax()
)


# 执行这个前先执行上一块，执行了这个以后就可以加载之前训练好的参数了，不用再重新训练了
model1 = pdl.Model(net1, inputs=[pdl.static.InputSpec(shape=[-1, 28, 28], dtype='float32', name='image')])
model2 = pdl.Model(net2, inputs=[pdl.static.InputSpec(shape=[-1, 28, 28], dtype='float32', name='image')])
model1.summary((1, 784))
model2.summary((1, 1, 28, 28))

model1.prepare(pdl.optimizer.Adam(learning_rate = 0.001,
parameters = net1.parameters()),
pdl.nn.CrossEntropyLoss(),
pdl.metric.Accuracy())

model2.prepare(pdl.optimizer.Adam(learning_rate = 0.001,
parameters = net2.parameters()),
pdl.nn.CrossEntropyLoss(),
pdl.metric.Accuracy())

model1.fit(training_set, testing_set, epochs = 10, batch_size = 128, verbose = 1)
result1 = model1.evaluate(testing_set, verbose = 1)
model2.fit(training_set, testing_set, epochs = 10, batch_size = 128, verbose = 1)
result2 = model2.evaluate(testing_set, verbose = 1)
print(result1, result2)


model1.save('finetuning/mnist_NN')
model2.save('finetuning/mnist_LeNet')
# 结果已经保存

predict1 = model1.predict(testing_set)
predict2 = model2.predict(testing_set)
# 经观察这些结果每一个都是预测的概率，需要提取出最大的一个作为预测结果，另外，外面依然有层壳

def show_img(img, predict):
    plt.figure()
    plt.title('predict: {}'.format(predict))
    plt.imshow(img.reshape([28,28]), cmap=plt.cm.binary)
    plt.show()
    
import random
indexs = random.randint(0, 2000) * np.array(range(1, 6))
print(indexs)

for idx in indexs:
    show_img(testing_set[idx][0], 'NN:{},CNN:{}|Truth:{}'.format(np.argmax(predict1[0][idx]), np.argmax(predict2[0][idx]), testing_set[idx][1][0]))


# 加载自己写的图片进行预测，记得先执行上面的两个网络建模模块
model1.load('finetuning/mnist_NN')
model2.load('finetuning/mnist_LeNet')

import os
import PIL
import matplotlib.pyplot as plt
number = 10
dir_path = r"dig10"
files = os.listdir(dir_path)
# print(files)
for idx in range(number):
    if('0'<=files[idx][0]<='9'):
        image_path = dir_path + '/' + files[idx]
        image = PIL.Image.open(image_path)
        # plt.imshow(image)
        # plt.show()
        image = image.convert("L")
        image = image.resize((28, 28), PIL.Image.ANTIALIAS)
        image = np.array(image).reshape(1, 1, 28, 28).astype(np.float32)
        image = 255 - image #反相操作！非常重要！
        image = image / 255.0 * 2.0 - 1.0
        pred1 = model1.predict_batch(image)
        pred2 = model2.predict_batch(image)
        # show_img(image,'NN:{}, LeNet-5:{}'.format(np.argmax(pred1), np.argmax(pred2)))
        print("神经网络预测数字为：{}".format(np.argmax(pred1)),end=",")
        print("卷积神经网络预测数字为：{}".format(np.argmax(pred2)))
        print("实际数字为：{}".format(files[idx].split(".")[0]))

```



tensorflow代码:
```python

import os
import sys
import tensorflow as tf
import numpy as np
# import tensorflow.compat.v1 as tf  # 降级为1.x版本
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense,Flatten
from  tensorflow.keras.models import load_model
np.set_printoptions(threshold=np.inf)  #np.inf表示无限大

mnist=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train,x_test=x_train/255.0,x_test/255.0


class MnistModel(Model):
    def __init__(self):
        super(MnistModel, self).__init__()
        self.flatten = Flatten()
        self.d1 = Dense(128, activation='relu')
        self.d2 = Dense(10, activation='softmax')

    def call(self, x):
        x = self.flatten(x)
        x = self.d1(x)
        y = self.d2(x)
        return y

# 用自定义函数无法直接保存成h5格式 model.save('model.h5')
# model = MnistModel()

#默认用函数来定义模型
model=tf.keras.models.Sequential([tf.keras.layers.Flatten(),
                                  tf.keras.layers.Dense(128,activation='relu'),
                                  tf.keras.layers.Dense(10,activation='softmax')])


model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['sparse_categorical_accuracy'])

# 保存断点，继续训练
checkpoint_save_path = './checkpoint/mnist.ckpt'
if os.path.exists(checkpoint_save_path + '.index'):
    print("----------load the model----------")
    model.load_weights(checkpoint_save_path)
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path, save_weights_only=True,save_best_only=True)


# 训练模型
# model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_test,y_test),validation_freq=1)
history=model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_test,y_test),validation_freq=1,callbacks = [cp_callback])
model.summary()


# 打印并保存参数
print(model.trainable_variables)
file=open('./weights.txt','w')
for v in model.trainable_variables:
    file.write(str(v.name)+"\n")
    file.write(str(v.shape)+'\n')
    file.write(str(v.numpy())+'\n')

file.close()


'''---------------画图---------------'''
import matplotlib.pyplot as plt
# 显示训练集和验证集的acc和loss曲线
acc=history.history['sparse_categorical_accuracy']
val_acc=history.history['val_sparse_categorical_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

plt.subplot(1,2,1)
plt.plot(acc,label='Training Accuracy')
plt.plot(val_acc,label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()


plt.subplot(1,2,2)
plt.plot(loss,label='Training Loss')
plt.plot(val_loss,label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()


# 对模型初步预测，对训练过程的部分数据进行保存，以及对模型保存成.h5格式，以便于后续的调用。
import pickle

# 模型预测
print("测试神经网络:")
score, acc = model.evaluate(x_test, y_test, batch_size=32)
print('Test score:', score)
print('Test accuracy:', acc)
# 训练记录保存
with open('history.txt', 'wb', ) as file_txt:
    pickle.dump(history.history, file_txt)
# 模型保存.h5
# 如果用自定义类，无法直接保存成h5格式
model.save('model.h5')  # 保存了模型的图结构和模型的参数，保存模型的后缀是.hdf5
# model.save('model.hdf5')  # 保存了模型的图结构和模型的参数，保存模型的后缀是.hdf5
# model.save_weights('model_weights.h5')  # 只保存了模型的参数，并没有保存模型的图结构,保存模型的后缀使用.h5


# 简单的模型运用

'''
from tensorflow.keras.models import load_model
import numpy as np

# 模型的导入
model = load_model('model.h5')

# 测试第几张图片
pic_index=0


from PIL import Image
import matplotlib.pyplot as plt
# infer_path='/home/aistudio/data/data2394/infer_3.png'
# img = Image.open(infer_path)
img=x_test[pic_index]
plt.imshow(img)   #根据数组绘制图像
plt.show()        #显示图像

# 预测图片
# predictions=model.predict([x_test[5:8]])#识别测试集中第6到8张图片
predictions=model.predict([x_test[pic_index:pic_index+1]])#识别测试集中第6到8张图片
for x in predictions:
    print(x)
    print("预测数字为:", np.argmax(x) )

'''

from PIL import Image

model_save_path = './checkpoint/mnist.ckpt'
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
# load_weight需要重建模型
model.load_weights(model_save_path)

preNum = int(input("请输入要预测几张图:"))
for i in range(preNum):
    image_path = input("请输入图片的路径:")
    img = Image.open(image_path)
    # 重新定义输入大小，以便和训练的模型输入相同
    img = img.resize((28, 28), Image.ANTIALIAS)
    img_arr = np.array(img.convert('L'))

    # 图片预处理
    # 白底黑字，变成黑底白字
    # img_arr=255-img_arr

    for i in range(28):
        for j in range(28):
            if img_arr[i][j] < 200:
                img_arr[i][j] = 255
            else:
                img_arr[i][j] = 0

    img_arr = img_arr / 255.0

    #显示图片
    plt.imshow(img_arr)  # 根据数组绘制图像
    plt.show()  # 显示图像

    # 升维度
    # 为什么要升维度：由于predict是按照batch作为输入的，在这里batch是1，即我们输入的那张图片，所以应该要升维度1，且该维度在最前面
    x_predict = img_arr[tf.newaxis, ...]
    result=model.predict(x_predict)
    pred = tf.argmax(result, axis=1)
    print('预测结果\n')
    tf.print(pred)
    print('\n')


```


