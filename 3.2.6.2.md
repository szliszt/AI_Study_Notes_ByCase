# 使用预训练模型Ernie进行商品分类



# 一、安装环境

```python
!pip install --upgrade paddlehub -i https://pypi.tuna.tsinghua.edu.cn/simple
```


```python
import paddlehub as hub
import paddle
print("题目1:查看Paddle、PaddleHub版本以及模型信息")
print(paddle.__version__)
# !pip show paddlehub
```


## 二、准备数据

```python
# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原
1、下载分类训练的数据，下载地址 https://aistudio.baidu.com/aistudio/datasetdetail/135131
2、上传 train.txt,valid.txt,test.txt 到 work/goods/目录

# 调整train的列顺序，从 label,text_a 改成text_a,label
import pandas as pd 
pd.read_csv("work/goods/train.txt",sep="\t")[["text_a","label"]].to_csv("work/goods/train.txt",sep="\t",index=False)
# 调整test的列顺序，从 label,text_a 改成text_a,label
pd.read_csv("work/goods/test.txt",sep="\t")[["text_a","label"]].to_csv("work/goods/test.txt",sep="\t",index=False)

# 统计有多少标签
import pandas as pd 
label_list=pd.read_csv("work/goods/train.txt",sep="\t")["label"].unique().tolist()


# 另外一种写法
# import csv 
# file =open('work/goods/test.txt','r')
# reader=csv.reader(file)
# header_row=next(reader)
# row=[]#定义行数组
# for line in reader:
#     row.append("".join(line).split('\t')[1])  # 去到第二列，字段用\t做分隔符
# label_list = list( set(row) ) # 去除重复记录
# file.close()


# # 分类器
class_dim=len(label_list)
print("品类总数：", class_dim)
print("品类列表：",label_list)



```


## 三、训练模型


```python
model = hub.Module(name="ernie", task='seq-cls', num_classes=class_dim) # 在多分类任务中，num_classes需要显式地指定类别数，此处根据数据集设置为14
print(model)

import os, io, csv
from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset

# 数据集存放位置
DATA_DIR="work/goods"


class ThuNews(TextClassificationDataset):
    def __init__(self, tokenizer, mode='train', max_seq_len=128):
        if mode == 'train':
            data_file = 'train.txt'
        elif mode == 'test':
            data_file = 'test.txt'
        else:
            data_file = 'valid.txt'
        super(ThuNews, self).__init__(
            base_path=DATA_DIR,
            data_file=data_file,
            tokenizer=tokenizer,
            max_seq_len=max_seq_len,
            mode=mode,
            is_file_with_header=True,
            label_list=label_list)

    # 解析文本文件里的样本
    def _read_file(self, input_file, is_file_with_header: bool = False):
        if not os.path.exists(input_file):
            raise RuntimeError("The file {} is not found.".format(input_file))
        else:
            with io.open(input_file, "r", encoding="UTF-8") as f:
                reader = csv.reader(f, delimiter="\t", quotechar=None)
                examples = []
                seq_id = 0
                header = next(reader) if is_file_with_header else None
                for line in reader:
                    example = InputExample(guid=seq_id, text_a=line[0], label=line[1])
                    seq_id += 1
                    examples.append(example)
                return examples

train_dataset = ThuNews(model.get_tokenizer(), mode='train', max_seq_len=128)
dev_dataset = ThuNews(model.get_tokenizer(), mode='dev', max_seq_len=128)
test_dataset = ThuNews(model.get_tokenizer(), mode='test', max_seq_len=128)
for e in train_dataset.examples[:3]:
    print(e)
 
optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())  # 优化器的选择和参数配置
trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=False)        # fine-tune任务的执行者

trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset, save_interval=1)   

```



## 四、评估模型

```python
result = trainer.evaluate(test_dataset, batch_size=32)    # 在测试集上评估当前训练模型
```


## 五、预测结果

```python
# 统计有多少标签
label_list=pd.read_csv("work/goods/train.txt",sep="\t")["label"].unique().tolist()

# Data to be prdicted
data = [
    # 休闲食品
    [
        "640G正航牛奶早餐饼干"],
    # 个护
    [
        "潘婷丝质顺滑洗发露750ml"],
    # 粮油速食
    [
        "风味坐标 三鲜狮子头200g/2只 内含两枚Q弹大肉丸 送清汤料包 加热即食 半成品方便"],
    # 家电
    [
        "美的电热水壶304不锈钢MK-SP50Colour201	"]
]

label_map = {
    idx: label_text for idx, label_text in enumerate(label_list)
}

model = hub.Module(
    name='ernie',
    task='seq-cls',
    load_checkpoint='./ckpt/best_model/model.pdparams',
    label_map=label_map)
results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=True)
for idx, text in enumerate(data):
    print('Data: {} \t Lable: {}'.format(text[0], results[idx]))
    
```

